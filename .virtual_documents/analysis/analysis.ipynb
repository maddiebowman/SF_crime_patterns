# Import dependecies
import pandas as pd
import os
import csv
import matplotlib.pyplot as plt


# Read in data
csv_path = os.path.join("../data/Police_Department_Incident_Reports.csv")
crime_df = pd.read_csv(csv_path)

# Show first 10 rows of DataFrame
crime_df.head(10)


# Check that data was successfully imported by counting rows
num_rows = len(crime_df)
print("Number of rows in the DataFrame:", num_rows)


# Determine datatypes for each column
print(crime_df.dtypes)


# Drop unwanted columns and corss-reference to original DataFrame
print("Original DataFrame:")
print("-------------------")
print(crime_df.dtypes)

columns_to_drop = ['Report Datetime',
                   'Row ID',
                   'Incident ID',
                   'Incident Number',
                   'CAD Number',
                   'Report Type Code',
                   'Report Type Description',
                   'Filed Online',
                   'Incident Code',
                   'Intersection',
                   'CNN',
                   'Police District',
                   'Supervisor District',
                   'Supervisor District 2012',
                   'Point',
                   'Neighborhoods',
                   'ESNCAG - Boundary File',
                   'Central Market/Tenderloin Boundary Polygon - Updated',
                   'Civic Center Harm Reduction Project Boundary',
                   'HSOC Zones as of 2018-06-05',
                   'Invest In Neighborhoods (IIN) Areas',
                   'Current Supervisor Districts',
                   'Current Police Districts']

crime_new_df = crime_df.drop(columns=columns_to_drop)

print("\nNew DataFrame:")
print("-------------------")
print(crime_new_df.dtypes)


# View new DataFrame
crime_new_df.head(5)



# Remove rows with null values for latitude, longitude, and analysis neighborhood
crime_new_df = crime_new_df.dropna(subset=['Longitude', 'Latitude', 'Analysis Neighborhood'])
crime_new_df.head(5)


# Find the different incident types, count each occurance in dataset
unique_counts = crime_new_df["Incident Category"].value_counts()
unique_incidents_df = pd.DataFrame(unique_counts.items(), columns=["Unique_Values", "Counts"])

# Display the categories and their counts
unique_incidents_df


# List of categories to remove
categories_to_remove = [
    'Non-Criminal', 'Case-Closure', 'Vehicle-Misplaced',
    'Suicide', 'Civil Sidewalks', 'Traffic Collision', 'Liquor Laws'
]

# Remove rows where 'Incident Category' is in the list of categories to remove
crime_new_df = crime_new_df[~crime_new_df['Incident Category'].isin(categories_to_remove)]

# Display the DataFrame to confirm the changes
crime_new_df.head(5)


# Count the total incidents for each 'Analysis Neighborhood'
neighborhood_incident_counts = crime_new_df['Analysis Neighborhood'].value_counts()

# Display the counts
print(neighborhood_incident_counts)


# Bar chart to show least safe neighborhoods SF

# Plot the bar chart
plt.figure(figsize=(12, 8))
neighborhood_incident_counts.plot(kind='bar')
plt.title('Total Incidents by Analysis Neighborhood')
plt.xlabel('Analysis Neighborhood')
plt.ylabel('Total Incidents')
plt.xticks(rotation=90) 
plt.tight_layout()

# Show the plot
plt.show()


# Find the top 10 neighborhoods with the most incidents
top_neighborhood_crime_counts = crime_new_df['Analysis Neighborhood'].value_counts().nlargest(10)


# List of neighborhoods with the most amount of incidents, convert to DF
least_safe_neighborhoods_df = pd.DataFrame(top_neighborhood_crime_counts)

print("Neighborhoods with the most amount of incidents:")
least_safe_neighborhoods_df.head(10)


# Pie chart to show the top 10 neighborhoods with the most incidents

# Plot the pie chart
plt.figure(figsize=(10, 8))
top_neighborhood_crime_counts.plot(kind='pie', autopct='%1.1f%%')
plt.title('Percentage of Incidents by Analysis Neighborhood')
plt.ylabel('')
plt.tight_layout()

# Show the plot
plt.show()


# Find the safest neighborhoods in San Francisco
neighborhoods_least_incidents = neighborhood_incident_counts.nsmallest(10) 

safe_neighborhoods_df = pd.DataFrame(neighborhoods_least_incidents)

# Display the neighborhoods with the least amount of incidents
print("Neighborhoods with the least amount of incidents:")
safe_neighborhoods_df.head(10)


# Create new DataFrames for yearly data analysis

# List of years to access from df
years = [2019, 2020, 2021, 2022, 2023, 2024]

# Create dictionary to hold DataFrames for each year
crime_df_by_year = {}

# Create a new DataFrame for each year and store in the dictionary
for year in years:
    crime_df_by_year[year] = crime_new_df[crime_new_df['Incident Year'] == year]

# Display the DataFrame for 2024 to confirm
crime_df_2024 = crime_df_by_year[2024]
crime_df_2024.head(5)


# See neighborhood data for 2024
neighborhood_crime_counts_2024 = crime_df_2024['Analysis Neighborhood'].value_counts()

# Display the counts
print(neighborhood_crime_counts_2024)


# Tenderloin crime data
tenderloin_crime_2024 = crime_df_2024[crime_df_2024['Analysis Neighborhood'] == 'Tenderloin']['Incident Category']

# Create a DataFrame from the filtered data
tenderloin_crime_2024 = crime_df_2024[crime_df_2024['Analysis Neighborhood'] == 'Tenderloin']['Incident Category']

# Group the incident subcategories and count the occurrences of each
tenderloin_crime_2024_counts = tenderloin_crime_2024.value_counts().reset_index()
tenderloin_crime_2024_counts.columns = ['Incident Category', 'Count']

# Display the DataFrame with incident counts for Tenderloin
print("Tenderloin Crime Breakdown for 2024:")
tenderloin_crime_2024_counts.head(50)


# Find the different incident types, count each occurance in dataset
unique_category_counts = crime_df_2024["Incident Category"].value_counts()
current_unique_incidents_df = pd.DataFrame(unique_category_counts.items(), columns=["Unique_Values", "Counts"])

# Display the categories and their counts
current_unique_incidents_df



